# llama-cpp-chat-memory
Llamacpp chat with langchain and chainlit using vector stores as memory.
